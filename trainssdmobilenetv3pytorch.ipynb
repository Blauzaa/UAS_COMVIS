{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# SEL 1: KONFIGURASI EKSPERIMEN (Pusat Kendali Anda)\n",
    "# ===================================================================\n",
    "import os\n",
    "\n",
    "# --- Atur variabel lingkungan (HARUS PALING ATAS) ---\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# --- 1. PILIH PENGATURAN EKSPERIMEN ANDA DI SINI ---\n",
    "MODEL_BASE_NAME = \"ssdmobilenetv3_statis_baseline_albuminatinon_test\"\n",
    "EPOCHS = 70\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.001\n",
    "# Catatan: Jika BS=8, LR=0.002. Jika BS=16, LR=0.004\n",
    "\n",
    "# --- 2. PENGATURAN PROYEK (biasanya tidak perlu diubah) ---\n",
    "DATASET_ROOT = 'dataset'\n",
    "CLASSES_TO_USE = [\n",
    "    'baguette', 'cornbread', 'croissant', 'ensaymada', 'flatbread',\n",
    "    'sourdough', 'wheat-bread', 'white-bread', 'whole-grain-bread', 'pandesal'\n",
    "]\n",
    "NUM_CLASSES = len(CLASSES_TO_USE)\n",
    "\n",
    "# --- 3. NAMA FOLDER DAN PATH DIBUAT SECARA OTOMATIS ---\n",
    "lr_str = str(LEARNING_RATE).replace('.', '_')\n",
    "PROJECT_NAME = f\"{MODEL_BASE_NAME}_e{EPOCHS}_bs{BATCH_SIZE}_lr{lr_str}\"\n",
    "WORK_DIR = f\"outputs/{PROJECT_NAME}\"\n",
    "\n",
    "# Cetak konfigurasi untuk verifikasi\n",
    "print(\"=\"*60)\n",
    "print(\"KONFIGURASI EKSPERIMEN AKTIF:\")\n",
    "print(f\"  - Nama Proyek: {PROJECT_NAME}\")\n",
    "print(f\"  - Direktori Kerja: {WORK_DIR}\")\n",
    "print(f\"  - Epoch: {EPOCHS}\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Learning Rate: {LEARNING_RATE}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c06081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# SEL 2: INSTALASI, IMPORT, DAN PERSIAPAN HELPER (VERSI BASELINE)\n",
    "# ===================================================================\n",
    "import sys, json, torch, numpy as np, pandas as pd, requests\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# --- 1. MEMBUAT FILE transforms.py KUSTOM (HANYA FLIP & TENSOR) ---\n",
    "content_transforms = r\"\"\"\n",
    "import random\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor as _ToTensor\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms): self.transforms = transforms\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms: image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "class ToTensor(_ToTensor):\n",
    "    def __call__(self, image, target):\n",
    "        image = F.to_tensor(image)\n",
    "        return image, target\n",
    "\n",
    "class RandomHorizontalFlip:\n",
    "    def __init__(self, prob=0.5): self.prob = prob\n",
    "    def __call__(self, image, target):\n",
    "        if random.random() < self.prob:\n",
    "            width, _ = image.size\n",
    "            image = F.hflip(image)\n",
    "            if \"boxes\" in target:\n",
    "                bbox = target[\"boxes\"]\n",
    "                bbox[:, [0, 2]] = width - bbox[:, [2, 0]]\n",
    "                target[\"boxes\"] = bbox\n",
    "        return image, target\n",
    "\"\"\"\n",
    "try:\n",
    "    with open('transforms.py', 'w') as f: f.write(content_transforms.strip())\n",
    "    print(\"File 'transforms.py' kustom (baseline) berhasil dibuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"GAGAL membuat 'transforms.py': {e}\")\n",
    "    \n",
    "# --- Sisa dari SEL 2 (tidak perlu diubah, bisa disalin dari versi final sebelumnya) ---\n",
    "# ... (Download utils.py, coco_utils.py, engine_robust.py, install pycocotools, dst.)\n",
    "# Untuk kejelasan, berikut kode lengkapnya:\n",
    "\n",
    "helper_files_to_download = {\n",
    "    'utils.py': 'https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py',\n",
    "    'engine_robust.py': 'https://gist.githubusercontent.com/renton-k5/7334bfe4352b2f6f1a8f815041071d72/raw/4373ca35d6c81308311a2f00d38a0b3b4f9f0612/engine_robust.py',\n",
    "    'coco_utils.py': 'https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py',\n",
    "    'coco_eval.py': 'https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py'\n",
    "}\n",
    "print(\"\\nMendownload sisa file helper...\")\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "for filename, url in helper_files_to_download.items():\n",
    "    if not os.path.exists(filename): # Hanya download jika belum ada\n",
    "        try:\n",
    "            r = requests.get(url)\n",
    "            r.raise_for_status()\n",
    "            with open(filename, 'w', encoding='utf-8') as f: f.write(r.text)\n",
    "            print(f\"File {filename} berhasil di-download.\")\n",
    "        except Exception as e:\n",
    "            print(f\"GAGAL men-download {filename}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {filename} sudah ada, download dilewati.\")\n",
    "print(\"\\nMenginstall pycocotools...\")\n",
    "!pip install pycocotools -q\n",
    "print(\"pycocotools terinstall.\")\n",
    "import torchvision\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large\n",
    "from torchvision.models.detection.ssdlite import SSDLiteClassificationHead\n",
    "from engine_robust import train_one_epoch, evaluate_robust as evaluate\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b629de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# SEL 3: PEMROSESAN DATA (FILTER ANOTASI)\n",
    "# ===================================================================\n",
    "def filter_coco_annotations(original_ann_file, new_ann_file, classes_to_keep):\n",
    "    if os.path.exists(new_ann_file):\n",
    "        print(f\"File anotasi terfilter sudah ada: {new_ann_file}\")\n",
    "        return\n",
    "    with open(original_ann_file, 'r') as f: coco_data = json.load(f)\n",
    "    print(f\"Memfilter {original_ann_file}...\")\n",
    "    original_categories = {cat['name']: cat['id'] for cat in coco_data['categories']}\n",
    "    new_categories, old_id_to_new_id, new_cat_id = [], {}, 1\n",
    "    for cat_name in classes_to_keep:\n",
    "        if cat_name in original_categories:\n",
    "            new_categories.append({'id': new_cat_id, 'name': cat_name, 'supercategory': 'object'})\n",
    "            old_id_to_new_id[original_categories[cat_name]] = new_cat_id\n",
    "            new_cat_id += 1\n",
    "    new_annotations, image_ids_with_annotations = [], set()\n",
    "    for ann in coco_data['annotations']:\n",
    "        if ann.get('iscrowd', 0) == 0 and ann['category_id'] in old_id_to_new_id:\n",
    "            ann['category_id'] = old_id_to_new_id[ann['category_id']]\n",
    "            new_annotations.append(ann)\n",
    "            image_ids_with_annotations.add(ann['image_id'])\n",
    "    new_images = [img for img in coco_data['images'] if img['id'] in image_ids_with_annotations]\n",
    "    new_coco_data = {'images': new_images, 'annotations': new_annotations, 'categories': new_categories}\n",
    "    os.makedirs(os.path.dirname(new_ann_file), exist_ok=True)\n",
    "    with open(new_ann_file, 'w') as f: json.dump(new_coco_data, f, indent=2)\n",
    "    print(f\"File anotasi baru disimpan di: {new_ann_file}\")\n",
    "\n",
    "original_train_ann = os.path.join(DATASET_ROOT, 'train', '_annotations.coco.json')\n",
    "filtered_train_ann = os.path.join(DATASET_ROOT, 'train', 'filtered_annotations.coco.json')\n",
    "original_valid_ann = os.path.join(DATASET_ROOT, 'valid', '_annotations.coco.json')\n",
    "filtered_valid_ann = os.path.join(DATASET_ROOT, 'valid', 'filtered_annotations.coco.json')\n",
    "\n",
    "filter_coco_annotations(original_train_ann, filtered_train_ann, CLASSES_TO_USE)\n",
    "filter_coco_annotations(original_valid_ann, filtered_valid_ann, CLASSES_TO_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3cef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# SEL 4: PEMBUATAN SKRIP train.py (DIPERBAIKI DENGAN ALBUMENTATIONS)\n",
    "# ===================================================================\n",
    "\n",
    "script_content = r\"\"\"\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
    "import sys, json, torch, numpy as np, pandas as pd, gc, argparse, cv2\n",
    "import torchvision\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large\n",
    "from torchvision.models.detection.ssdlite import SSDLiteClassificationHead\n",
    "import torch.utils.data\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "import utils\n",
    "from engine_robust import train_one_epoch, evaluate_robust as evaluate\n",
    "\n",
    "# --- PERUBAHAN DIMULAI DI SINI: Integrasi Albumentations ---\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "def get_transform(train):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            # Tambahkan rotasi. Sangat penting untuk mengatasi FN.\n",
    "            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.6),\n",
    "            \n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
    "            A.GaussianBlur(blur_limit=(3, 7), p=0.4),\n",
    "            \n",
    "            # CoarseDropout memaksa model melihat bagian roti yang berbeda\n",
    "            A.CoarseDropout(max_holes=8, max_height=25, max_width=25, p=0.5),\n",
    "\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ], bbox_params=A.BboxParams(\n",
    "            format='coco',\n",
    "            label_fields=['category_ids'],\n",
    "            min_visibility=0.2\n",
    "        ))\n",
    "    else:\n",
    "        # Validasi tetap sama\n",
    "        return A.Compose([\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "\n",
    "class BreadDataset(CocoDetection):\n",
    "    def __init__(self, root, annFile, transform=None):\n",
    "        super(BreadDataset, self).__init__(root, annFile)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, target_list = super(BreadDataset, self).__getitem__(idx)\n",
    "        \n",
    "        # Konversi PIL Image ke NumPy array (wajib untuk Albumentations)\n",
    "        image = np.array(img)\n",
    "        \n",
    "        boxes, labels, areas = [], [], []\n",
    "        \n",
    "        for ann in target_list:\n",
    "            x, y, w, h = ann['bbox']\n",
    "            # Filter anotasi yang tidak valid dari awal\n",
    "            if w > 0 and h > 0:\n",
    "                boxes.append([x, y, w, h])\n",
    "                labels.append(ann['category_id'])\n",
    "                areas.append(ann['area'])\n",
    "        \n",
    "        # Siapkan dictionary untuk augmentasi\n",
    "        transform_input = {\n",
    "            'image': image,\n",
    "            'bboxes': boxes,\n",
    "            'category_ids': labels\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(**transform_input)\n",
    "            image = transformed['image']\n",
    "            transformed_boxes = transformed['bboxes']\n",
    "            transformed_labels = transformed['category_ids']\n",
    "        else:\n",
    "            transformed_boxes = boxes\n",
    "            transformed_labels = labels\n",
    "\n",
    "        target = {}\n",
    "        # Menangani kasus di mana semua bounding box hilang setelah augmentasi\n",
    "        if len(transformed_boxes) > 0:\n",
    "            # Konversi format [x,y,w,h] ke [x1,y1,x2,y2] yang dibutuhkan model\n",
    "            boxes_xyxy = [[box[0], box[1], box[0] + box[2], box[1] + box[3]] for box in transformed_boxes]\n",
    "            target[\"boxes\"] = torch.as_tensor(boxes_xyxy, dtype=torch.float32)\n",
    "            target[\"labels\"] = torch.as_tensor(transformed_labels, dtype=torch.int64)\n",
    "            # Buat ulang area jika perlu (opsional, tergantung evaluator)\n",
    "            target[\"area\"] = torch.as_tensor([(b[2]-b[0])*(b[3]-b[1]) for b in boxes_xyxy], dtype=torch.float32)\n",
    "        else: \n",
    "            # Jika tidak ada box, buat tensor kosong untuk mencegah error\n",
    "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            target[\"labels\"] = torch.zeros(0, dtype=torch.int64)\n",
    "            target[\"area\"] = torch.zeros(0, dtype=torch.float32)\n",
    "\n",
    "        target[\"image_id\"] = torch.tensor([self.ids[idx]])\n",
    "        target[\"iscrowd\"] = torch.zeros((len(transformed_boxes),), dtype=torch.int64)\n",
    "\n",
    "        return image, target\n",
    "# --- PERUBAHAN SELESAI ---\n",
    "\n",
    "def freeze_bn(module):\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module.eval()\n",
    "        if module.weight is not None: module.weight.requires_grad = False\n",
    "        if module.bias is not None: module.bias.requires_grad = False\n",
    "\n",
    "def main(args):\n",
    "    model_base_name = args.model_base_name\n",
    "    lr_str = str(args.lr).replace('.', '_')\n",
    "    PROJECT_NAME = f\"{model_base_name}_e{args.epochs}_bs{args.batch_size}_lr{lr_str}\"\n",
    "    DATASET_ROOT = 'dataset'\n",
    "    CLASSES_TO_USE = ['baguette', 'cornbread', 'croissant', 'ensaymada', 'flatbread', 'sourdough', 'wheat-bread', 'white-bread', 'whole-grain-bread', 'pandesal']\n",
    "    NUM_CLASSES = len(CLASSES_TO_USE)\n",
    "    WORK_DIR = f\"outputs/{PROJECT_NAME}\"\n",
    "    os.makedirs(WORK_DIR, exist_ok=True)\n",
    "    print(\"=\"*60 + f\"\\nMemulai Eksperimen: {PROJECT_NAME}\\n\" + \"=\"*60)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    dataset = BreadDataset(os.path.join(DATASET_ROOT, 'train'), os.path.join(DATASET_ROOT, 'train', 'filtered_annotations.coco.json'), transform=get_transform(train=True))\n",
    "    dataset_test = BreadDataset(os.path.join(DATASET_ROOT, 'valid'), os.path.join(DATASET_ROOT, 'valid', 'filtered_annotations.coco.json'), transform=get_transform(train=False))\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=2, collate_fn=utils.collate_fn, drop_last=True)\n",
    "    data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=2, collate_fn=utils.collate_fn)\n",
    "    \n",
    "    model = ssdlite320_mobilenet_v3_large(weights='DEFAULT')\n",
    "    num_anchors = model.anchor_generator.num_anchors_per_location()\n",
    "    in_channels = [m[0][0].in_channels for m in model.head.classification_head.module_list]\n",
    "    new_head = SSDLiteClassificationHead(in_channels=in_channels, num_anchors=num_anchors, num_classes=(NUM_CLASSES + 1), norm_layer=torch.nn.BatchNorm2d)\n",
    "    model.head.classification_head = new_head\n",
    "    model.to(device)\n",
    "    \n",
    "    # SARAN: Coba jalankan SATU KALI TANPA freeze_bn untuk melihat perbedaannya\n",
    "    # model.apply(freeze_bn) \n",
    "    \n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=args.lr, momentum=0.9, weight_decay=0.0005)\n",
    "    \n",
    "    # --- AKTIFKAN KEMBALI LR SCHEDULER ---\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=1e-6)\n",
    "    \n",
    "    print(f\"--- MEMULAI TRAINING {args.epochs} EPOCH (DENGAN ALBUMENTATIONS & LR SCHEDULER) ---\")\n",
    "    best_map = 0.0\n",
    "    training_history = []\n",
    "    for epoch in range(args.epochs):\n",
    "        metric_logger = train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=50)\n",
    "        \n",
    "        # Panggil scheduler setelah setiap epoch training\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        eval_result = evaluate(model, data_loader_test, device=device)\n",
    "        current_map = eval_result.coco_eval['bbox'].stats[0]\n",
    "        # Catat learning rate yang sekarang digunakan\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        training_history.append({'epoch': epoch + 1, 'loss': metric_logger.meters['loss'].global_avg, 'mAP_0.50:0.95': current_map, 'lr': current_lr})\n",
    "        print(f\"Epoch {epoch+1}/{args.epochs}: Avg Loss={metric_logger.meters['loss'].global_avg:.4f}, mAP={current_map:.4f}, LR={current_lr:.6f}\")\n",
    "        \n",
    "        if current_map > best_map:\n",
    "            best_map = current_map\n",
    "            utils.save_on_master(model.state_dict(), os.path.join(WORK_DIR, 'best_model.pth'))\n",
    "            print(f\"*** Best mAP updated: {best_map:.4f} (model saved) ***\")\n",
    "    \n",
    "    print(f\"\\n--- TRAINING SELESAI --- Best mAP: {best_map:.4f}\")\n",
    "    pd.DataFrame(training_history).to_csv(os.path.join(WORK_DIR, 'training_log.csv'), index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model-base-name', type=str, default=\"ssdmobilenetv3\")\n",
    "    parser.add_argument('--epochs', type=int, default=70)\n",
    "    parser.add_argument('--batch-size', type=int, default=8)\n",
    "    parser.add_argument('--lr', type=float, default=0.001)\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    with open('train.py', 'w', encoding='utf-8') as f: f.write(script_content.strip())\n",
    "    print(\">>> Skrip 'train.py' (diperbaiki dengan Albumentations & LR Scheduler) berhasil dibuat.\")\n",
    "except Exception as e:\n",
    "    print(f\">>> GAGAL membuat skrip 'train.py': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# SEL 5: JALANKAN TRAINING (VERSI DIPERBAIKI)\n",
    "# ===================================================================\n",
    "import subprocess\n",
    "import sys  # <-- TAMBAHKAN BARIS INI\n",
    "\n",
    "# Perintah ini akan secara otomatis menggunakan variabel dari SEL 1\n",
    "command = [\n",
    "    sys.executable, \"-u\", \"train.py\",\n",
    "    \"--model-base-name\", MODEL_BASE_NAME,\n",
    "    \"--epochs\", str(EPOCHS),\n",
    "    \"--batch-size\", str(BATCH_SIZE),\n",
    "    \"--lr\", str(LEARNING_RATE)\n",
    "]\n",
    "\n",
    "# Jalankan proses\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, encoding='utf-8', bufsize=1)\n",
    "print(f\"--- Memulai eksekusi: {' '.join(command)} ---\")\n",
    "if process.stdout:\n",
    "    for line in iter(process.stdout.readline, ''): print(line, end='')\n",
    "return_code = process.wait()\n",
    "print(f\"\\n--- Eksekusi selesai dengan kode: {return_code} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# SEL 6: ANALISIS HASIL LENGKAP (PLOT, INFERENSI, METRIK) - FIX NameError\n",
    "# ===================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large\n",
    "from torchvision.models.detection.ssdlite import SSDLiteClassificationHead\n",
    "\n",
    "import transforms as CustomT\n",
    "import utils # <-- PERBAIKAN: TAMBAHKAN IMPORT INI\n",
    "\n",
    "# --- 1. PLOTTING KURVA STABILITAS ---\n",
    "# ... (sisa kode plotting tidak berubah) ...\n",
    "log_path = os.path.join(WORK_DIR, 'training_log.csv')\n",
    "print(f\"\\n>>> Membuat grafik dari: {log_path}...\")\n",
    "if os.path.exists(log_path):\n",
    "    log_df = pd.read_csv(log_path)\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "    ax1.set_xlabel('Epoch'); ax1.set_ylabel('Rata-rata Training Loss', color='tab:red')\n",
    "    ax1.plot(log_df['epoch'], log_df['loss'], 'o-', color='tab:red')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:red'); ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Validation mAP (0.50:0.95)', color='tab:blue')\n",
    "    ax2.plot(log_df['epoch'], log_df['mAP_0.50:0.95'], 's-', color='tab:blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    plt.title(f'Kurva Stabilitas Training: {PROJECT_NAME}')\n",
    "    plot_path = os.path.join(WORK_DIR, 'training_stability_curve.png')\n",
    "    plt.savefig(plot_path, dpi=200)\n",
    "    print(f\">>> Grafik disimpan di: {plot_path}\")\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"File log tidak ditemukan. Plotting dilewati.\")\n",
    "\n",
    "\n",
    "# --- 2. PERSIAPAN UNTUK ANALISIS LANJUTAN ---\n",
    "best_model_path = os.path.join(WORK_DIR, 'best_model.pth')\n",
    "REPORT_DIR = os.path.join(WORK_DIR, 'post_training_reports')\n",
    "os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    # --- A. BUAT ULANG SEMUA KOMPONEN YANG DIBUTUHKAN ---\n",
    "    print(f\"\\nModel terbaik ditemukan. Mempersiapkan untuk analisis mendalam...\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Buat ulang model dengan arsitektur yang benar, lalu muat bobot\n",
    "    model = ssdlite320_mobilenet_v3_large(weights='DEFAULT')\n",
    "    num_anchors = model.anchor_generator.num_anchors_per_location()\n",
    "    in_channels = [m[0][0].in_channels for m in model.head.classification_head.module_list]\n",
    "    new_head = SSDLiteClassificationHead(in_channels=in_channels, num_anchors=num_anchors, num_classes=(NUM_CLASSES + 1), norm_layer=torch.nn.BatchNorm2d)\n",
    "    model.head.classification_head = new_head\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model berhasil dimuat dari: {best_model_path}\")\n",
    "    \n",
    "    # --- B. INFERENSI PADA GAMBAR ACAK (DENGAN NAMA FILE AMAN) ---\n",
    "    print(\"\\n>>> Melakukan inferensi pada gambar acak...\")\n",
    "    INFERENCE_DIR = os.path.join(WORK_DIR, 'inference_results'); os.makedirs(INFERENCE_DIR, exist_ok=True)\n",
    "    valid_img_dir = os.path.join(DATASET_ROOT, 'valid')\n",
    "    all_valid_imgs = [f for f in os.listdir(valid_img_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if all_valid_imgs:\n",
    "        random_samples = random.sample(all_valid_imgs, k=min(5, len(all_valid_imgs)))\n",
    "        category_map = {i+1: name for i, name in enumerate(CLASSES_TO_USE)}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for img_name in random_samples:\n",
    "                img_path = os.path.join(valid_img_dir, img_name)\n",
    "                img_pil = Image.open(img_path).convert(\"RGB\")\n",
    "                \n",
    "                img_tensor, _ = CustomT.Compose([CustomT.ToTensor()])(img_pil, None)\n",
    "                prediction = model(img_tensor.unsqueeze(0).to(device))[0]\n",
    "                \n",
    "                original_image_cv = cv2.imread(img_path)\n",
    "                score_thr = 0.5\n",
    "                \n",
    "                detections = []\n",
    "                for i in range(len(prediction['scores'])):\n",
    "                    score = prediction['scores'][i].item()\n",
    "                    if score > score_thr:\n",
    "                        box = [int(coord) for coord in prediction['boxes'][i].tolist()]\n",
    "                        label_id = prediction['labels'][i].item()\n",
    "                        class_name = category_map.get(label_id, 'N/A')\n",
    "                        detections.append({'name': class_name, 'score': score})\n",
    "                        \n",
    "                        label_text = f\"{class_name}: {score:.2f}\"\n",
    "                        cv2.rectangle(original_image_cv, (box[0], box[1]), (box[2], box[3]), (36, 255, 12), 2)\n",
    "                        cv2.putText(original_image_cv, label_text, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (36, 255, 12), 2)\n",
    "                \n",
    "                vis_path = os.path.join(INFERENCE_DIR, f\"visualization_{img_name}\")\n",
    "                cv2.imwrite(vis_path, original_image_cv)\n",
    "                \n",
    "                base_name = os.path.splitext(img_name)[0]\n",
    "                sanitized_name = base_name.replace('.', '_')\n",
    "                summary_path = os.path.join(INFERENCE_DIR, f\"summary_{sanitized_name}.txt\")\n",
    "\n",
    "                with open(summary_path, 'w') as f:\n",
    "                    f.write(f\"Hasil Deteksi pada: {img_name}\\n\")\n",
    "                    f.write(f\"Score Threshold: {score_thr}\\n\" + \"=\"*30 + \"\\n\")\n",
    "                    if not detections:\n",
    "                        f.write(\"Tidak ada objek terdeteksi.\\n\")\n",
    "                    else:\n",
    "                        for det in sorted(detections, key=lambda x: x['score'], reverse=True):\n",
    "                            f.write(f\"- {det['name']}: {det['score']:.2f}\\n\")\n",
    "                    f.write(\"=\"*30 + f\"\\nTOTAL TERDETEKSI: {len(detections)}\\n\")\n",
    "\n",
    "        print(f\">>> Hasil inferensi (gambar & teks) disimpan di: {INFERENCE_DIR}\")\n",
    "\n",
    "    # --- C. ANALISIS MENDALAM (METRIK PER KELAS, DLL.) ---\n",
    "    print(\"\\n>>> Memulai evaluasi kustom untuk metrik per kelas...\")\n",
    "    \n",
    "    class AnalysisBreadDataset(CocoDetection):\n",
    "        def __init__(self, root, annFile, transform=None):\n",
    "            super().__init__(root, annFile); self.transform = transform\n",
    "        def __getitem__(self, idx):\n",
    "            img, target_list = super().__getitem__(idx)\n",
    "            boxes, labels = [], []\n",
    "            for ann in target_list:\n",
    "                x, y, w, h = ann['bbox']\n",
    "                if w>0 and h>0: boxes.append([x, y, x+w, y+h]); labels.append(ann['category_id'])\n",
    "            target = {\"boxes\": torch.as_tensor(boxes, dtype=torch.float32), \"labels\": torch.as_tensor(labels, dtype=torch.int64)}\n",
    "            if self.transform: img, target = self.transform(img, target)\n",
    "            target[\"image_id\"] = torch.tensor([self.ids[idx]])\n",
    "            return img, target\n",
    "\n",
    "    def get_analysis_transform(): return CustomT.Compose([CustomT.ToTensor()])\n",
    "            \n",
    "    dataset_test = AnalysisBreadDataset(os.path.join(DATASET_ROOT, 'valid'), os.path.join(DATASET_ROOT, 'valid', 'filtered_annotations.coco.json'), transform=get_analysis_transform())\n",
    "    \n",
    "    # Sekarang 'utils' sudah terdefinisi\n",
    "    data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=0, collate_fn=utils.collate_fn)\n",
    "    \n",
    "    # ... (sisa kode analisis mendalam tidak berubah) ...\n",
    "    n_classes = len(CLASSES_TO_USE)\n",
    "    conf_mat = np.zeros((n_classes, n_classes), dtype=np.int32)\n",
    "    per_class_counts = {'TP': np.zeros(n_classes), 'FP': np.zeros(n_classes), 'FN': np.zeros(n_classes)}\n",
    "    pr_store = {i: {'scores': [], 'match': []} for i in range(n_classes)}\n",
    "    iou_thr, score_thr = 0.5, 0.5\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(data_loader_test, desc=\"Mengevaluasi gambar\"):\n",
    "            outputs = model([img.to(device) for img in images])\n",
    "            for target, output in zip(targets, outputs):\n",
    "                gt_boxes, gt_labels = target['boxes'].numpy(), target['labels'].numpy()\n",
    "                keep = output['scores'] > score_thr\n",
    "                pred_boxes, pred_labels, pred_scores = output['boxes'][keep].cpu().numpy(), output['labels'][keep].cpu().numpy(), output['scores'][keep].cpu().numpy()\n",
    "                gt_matched = [False] * len(gt_boxes)\n",
    "                for i in range(len(pred_boxes)):\n",
    "                    best_iou, best_gt_idx = 0, -1\n",
    "                    for j in range(len(gt_boxes)):\n",
    "                        if gt_labels[j] == pred_labels[i]:\n",
    "                            iou = torchvision.ops.box_iou(torch.from_numpy(pred_boxes[i:i+1]), torch.from_numpy(gt_boxes[j:j+1])).item()\n",
    "                            if iou > best_iou: best_iou, best_gt_idx = iou, j\n",
    "                    pred_class_idx = pred_labels[i] - 1\n",
    "                    if best_iou >= iou_thr and best_gt_idx != -1 and not gt_matched[best_gt_idx]:\n",
    "                        gt_class_idx = gt_labels[best_gt_idx] - 1\n",
    "                        if 0 <= pred_class_idx < n_classes and 0 <= gt_class_idx < n_classes:\n",
    "                            conf_mat[gt_class_idx, pred_class_idx] += 1\n",
    "                            per_class_counts['TP'][pred_class_idx] += 1\n",
    "                            pr_store[pred_class_idx]['match'].append(1)\n",
    "                        gt_matched[best_gt_idx] = True\n",
    "                    else:\n",
    "                        if 0 <= pred_class_idx < n_classes:\n",
    "                            per_class_counts['FP'][pred_class_idx] += 1\n",
    "                            pr_store[pred_class_idx]['match'].append(0)\n",
    "                    if 0 <= pred_class_idx < n_classes:\n",
    "                        pr_store[pred_class_idx]['scores'].append(pred_scores[i])\n",
    "                for j in range(len(gt_boxes)):\n",
    "                    if not gt_matched[j]:\n",
    "                        gt_class_idx = gt_labels[j] - 1\n",
    "                        if 0 <= gt_class_idx < n_classes:\n",
    "                            per_class_counts['FN'][gt_class_idx] += 1\n",
    "    eps = 1e-12\n",
    "    prec = per_class_counts['TP'] / (per_class_counts['TP'] + per_class_counts['FP'] + eps)\n",
    "    rec = per_class_counts['TP'] / (per_class_counts['TP'] + per_class_counts['FN'] + eps)\n",
    "    f1 = 2 * prec * rec / (prec + rec + eps)\n",
    "    metrics_df = pd.DataFrame({'Kelas': CLASSES_TO_USE, 'TP': per_class_counts['TP'], 'FP': per_class_counts['FP'], 'FN': per_class_counts['FN'], 'Precision': prec, 'Recall': rec, 'F1-Score': f1})\n",
    "    metrics_df.to_csv(os.path.join(REPORT_DIR, \"per_class_metrics.csv\"), index=False)\n",
    "    print(f\"\\n>>> Metrik per kelas disimpan di: {REPORT_DIR}\\n{metrics_df}\")\n",
    "    plt.figure(figsize=(12, 10)); sns.heatmap(conf_mat, annot=True, fmt='d', cmap='viridis', xticklabels=CLASSES_TO_USE, yticklabels=CLASSES_TO_USE)\n",
    "    plt.title(f\"Confusion Matrix (IoU>{iou_thr}, Score>{score_thr})\"); plt.ylabel('True Label'); plt.xlabel('Predicted Label'); plt.tight_layout()\n",
    "    cm_path = os.path.join(REPORT_DIR, \"confusion_matrix.png\"); plt.savefig(cm_path, dpi=200); plt.close()\n",
    "    print(f\"\\n>>> Confusion matrix disimpan di: {cm_path}\")\n",
    "    pr_curve_dir = os.path.join(REPORT_DIR, 'pr_curves'); os.makedirs(pr_curve_dir, exist_ok=True)\n",
    "    for i, class_name in enumerate(CLASSES_TO_USE):\n",
    "        scores = np.array(pr_store[i]['scores']); matches = np.array(pr_store[i]['match'])\n",
    "        if len(scores) == 0: continue\n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(matches, scores)\n",
    "        plt.figure(); plt.plot(recall_vals, precision_vals, '-'); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR Curve - {class_name}\"); plt.grid(); plt.xlim(-0.05, 1.05); plt.ylim(-0.05, 1.05)\n",
    "        pr_path = os.path.join(pr_curve_dir, f\"pr_curve_{i:02d}_{class_name.replace(' ','_')}.png\"); plt.savefig(pr_path, dpi=200); plt.close()\n",
    "    print(f\">>> PR curves disimpan di: {pr_curve_dir}\")\n",
    "else:\n",
    "    print(f\"Analisis dilewati karena checkpoint terbaik tidak ditemukan di: {best_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roti_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
